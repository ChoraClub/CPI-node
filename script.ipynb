{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:46.619248Z",
     "iopub.status.busy": "2025-03-12T08:59:46.619248Z",
     "iopub.status.idle": "2025-03-12T08:59:47.539977Z",
     "shell.execute_reply": "2025-03-12T08:59:47.539977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the top 5000 delegates data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.544010Z",
     "iopub.status.busy": "2025-03-12T08:59:47.544010Z",
     "iopub.status.idle": "2025-03-12T08:59:47.549573Z",
     "shell.execute_reply": "2025-03-12T08:59:47.549573Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_top_5000_delegates():\n",
    "    \"\"\"\n",
    "    Fetches the top 5000 delegates using the skip parameter.\n",
    "    Converts the block timestamp and latest balance to readable formats.\n",
    "    Includes a 3-second timeout for API requests.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing delegate data.\n",
    "        filename\n",
    "    \"\"\"\n",
    "    # API endpoint\n",
    "    url = os.getenv('SUBGRAPH_ENDPOINT')\n",
    "\n",
    "    # GraphQL query template with a placeholder for skip value\n",
    "    query_template = \"\"\"\n",
    "    query MyQuery {{\n",
    "      delegates(orderBy: latestBalance, orderDirection: desc, first: 1000, skip: {skip_value}) {{\n",
    "        id\n",
    "        latestBalance\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    def fetch_data(skip_value):\n",
    "        \"\"\"\n",
    "        Executes the GraphQL query with the given skip value and returns the fetched data.\n",
    "        Includes a 3-second timeout.\n",
    "        \"\"\"\n",
    "        query = query_template.format(skip_value=skip_value)\n",
    "        try:\n",
    "            response = requests.post(url, json={\"query\": query}, timeout=5)  # Added 3-second timeout\n",
    "            response.raise_for_status()  # Raise an error for HTTP issues\n",
    "        except requests.Timeout:\n",
    "            print(f\"Request timed out for skip={skip_value}\")\n",
    "            raise\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Request failed for skip={skip_value}: {e}\")\n",
    "            raise\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        # Handle GraphQL errors\n",
    "        if \"errors\" in result:\n",
    "            print(\"GraphQL Error:\", result[\"errors\"])\n",
    "            raise ValueError(\"GraphQL query failed.\")\n",
    "\n",
    "        return result.get(\"data\", {}).get(\"delegates\", [])\n",
    "\n",
    "    # Initialize variables for pagination\n",
    "    all_data = []  # To store all results\n",
    "    skip = 0       # Start with skip=0\n",
    "    batch_size = 1000\n",
    "\n",
    "    while len(all_data) < 5000:\n",
    "        try:\n",
    "            # Fetch data for the current skip value\n",
    "            data = fetch_data(skip)\n",
    "        except (requests.Timeout, requests.RequestException) as e:\n",
    "            print(f\"Error fetching data for skip={skip}: {e}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error for skip={skip}: {e}\")\n",
    "            break\n",
    "\n",
    "        if not data:  # Exit if no more data is returned\n",
    "            break\n",
    "\n",
    "        all_data.extend(data)\n",
    "\n",
    "        # Increment skip by batch size\n",
    "        skip += batch_size\n",
    "\n",
    "        # Stop if we've fetched 5000 records\n",
    "        if len(all_data) >= 5000:\n",
    "            all_data = all_data[:5000]  # Trim excess records\n",
    "            break\n",
    "\n",
    "    if all_data:\n",
    "        # Convert the data to a DataFrame\n",
    "        df = pd.DataFrame(all_data)\n",
    "\n",
    "        # Rename columns to match the required names\n",
    "        df.rename(columns={\"id\": \"delegate\", \"latestBalance\": \"voting_power\"}, inplace=True)\n",
    "\n",
    "        # Convert latestBalance by dividing by 10^18\n",
    "        df['voting_power'] = df[\"voting_power\"].astype(float) / 10**18\n",
    "        \n",
    "        # Get the current date in the format %Y-%m-%d\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Save the dataframe to CSV with the current date as the filename\n",
    "        filepath = f\"./Data/{current_date}.csv\"\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "        # Extract the filename from the path\n",
    "        filename = os.path.basename(filepath)\n",
    "\n",
    "        return df, filename\n",
    "    else:\n",
    "        print(\"No data fetched. Returning an empty DataFrame.\")\n",
    "        return pd.DataFrame(), None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute the Power of ACC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.553590Z",
     "iopub.status.busy": "2025-03-12T08:59:47.553590Z",
     "iopub.status.idle": "2025-03-12T08:59:47.558545Z",
     "shell.execute_reply": "2025-03-12T08:59:47.558545Z"
    }
   },
   "outputs": [],
   "source": [
    "def distribute_ACC_Power(delegates, filename):\n",
    "    \"\"\"\n",
    "    Process a single delegate file by distributing voting power and removing the ACC delegate.\n",
    "\n",
    "    Parameters:\n",
    "    - delegate_file_path (str): Path to the delegate data CSV file.\n",
    "    \"\"\"\n",
    "    acc_file_path = \"./Data/Anticapture_Commission.csv\"\n",
    "\n",
    "    acc_delegate_address = \"0x3eee61b92c36e97be6319bf9096a1ac3c04a1466\"\n",
    "\n",
    "    # Load the ACC data\n",
    "    acc_data = pd.read_csv(acc_file_path, encoding='latin1')\n",
    "\n",
    "    # Extract the file date from the filename\n",
    "    file_date = datetime.strptime(os.path.basename(filename)[:-4], '%Y-%m-%d')\n",
    "\n",
    "    # Ensure dates in ACC data are in datetime format\n",
    "    acc_data.loc[:, 'start_date'] = pd.to_datetime(acc_data['start_date'], format='%Y-%m-%d')\n",
    "    acc_data.loc[:, 'end_date'] = pd.to_datetime(acc_data['end_date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Check if ACC delegate address is present in the delegates data\n",
    "    acc_delegate_row = delegates[delegates['delegate'].str.lower() == acc_delegate_address.lower()]\n",
    "    if acc_delegate_row.empty:\n",
    "        print(\"ACC delegate not found in the delegates data. Returning unmodified dataframe.\")\n",
    "        return delegates\n",
    "\n",
    "    # Filter ACC data by season\n",
    "    acc_season5 = acc_data[acc_data['season'] == 5]\n",
    "    acc_season6 = acc_data[acc_data['season'] == 6]\n",
    "    acc_season7 = acc_data[acc_data['season'] == 7]\n",
    "\n",
    "    # Determine the active season based on the file date\n",
    "    if (file_date >= acc_season5['start_date'].iloc[0]) and (file_date <= acc_season5['end_date'].iloc[0]):\n",
    "        active_season = acc_season5\n",
    "    elif (file_date >= acc_season6['start_date'].iloc[0]) and (file_date <= acc_season6['end_date'].iloc[0]):\n",
    "        active_season = acc_season6\n",
    "    elif (file_date >= acc_season7['start_date'].iloc[0]) and (file_date <= acc_season7['end_date'].iloc[0]):\n",
    "        active_season = acc_season7\n",
    "    else:\n",
    "        print(f\"File date {file_date} does not fall within any season. Returning unmodified dataframe.\")\n",
    "        return delegates\n",
    "\n",
    "    # Standardize address formats to lowercase\n",
    "    active_season['address'] = active_season['address'].str.lower()\n",
    "    delegates['delegate'] = delegates['delegate'].str.lower()\n",
    "\n",
    "    # Identify missing members from the active season and add them to the delegates dataframe\n",
    "    missing_members = active_season[~active_season['address'].isin(delegates['delegate'])]\n",
    "    missing_members_to_add = missing_members[['address']].rename(columns={'address': 'delegate'})\n",
    "    missing_members_to_add['voting_power'] = 0\n",
    "    updated_delegates = pd.concat([delegates, missing_members_to_add], ignore_index=True)\n",
    "\n",
    "    # Get the ACC delegate's voting power\n",
    "    acc_delegate_voting_power = acc_delegate_row['voting_power'].iloc[0]\n",
    "\n",
    "    # Distribute the ACC delegate's voting power among active season members\n",
    "    total_members = len(active_season)\n",
    "    voting_power_per_member = acc_delegate_voting_power / total_members\n",
    "    updated_delegates.loc[updated_delegates['delegate'].isin(active_season['address']),\n",
    "                          'voting_power'] += voting_power_per_member\n",
    "\n",
    "    # Remove the ACC delegate from the dataset\n",
    "    updated_delegates = updated_delegates[updated_delegates['delegate'] != acc_delegate_address.lower()]\n",
    "\n",
    "    # Sort the dataframe by voting power in descending order\n",
    "    sorted_data = updated_delegates.sort_values(by='voting_power', ascending=False).reset_index(drop=True)\n",
    "  \n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing members in the delegate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.562723Z",
     "iopub.status.busy": "2025-03-12T08:59:47.562723Z",
     "iopub.status.idle": "2025-03-12T08:59:47.568459Z",
     "shell.execute_reply": "2025-03-12T08:59:47.568459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to add missing delegates\n",
    "def add_missing_delegates(data, new_addresses):\n",
    "    missing_addresses = set(new_addresses['address'].str.lower()) - set(data['delegate'].str.lower())\n",
    "    missing_df = pd.DataFrame({\n",
    "        'delegate': list(missing_addresses),\n",
    "        'voting_power': 0\n",
    "    })\n",
    "    data = pd.concat([data, missing_df], ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dates to Datetime Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.573945Z",
     "iopub.status.busy": "2025-03-12T08:59:47.573945Z",
     "iopub.status.idle": "2025-03-12T08:59:47.577254Z",
     "shell.execute_reply": "2025-03-12T08:59:47.577254Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_dates(df):\n",
    "    \"\"\"\n",
    "    Converts the 'start_date' and 'end_date' columns to datetime format for a given dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataframe containing 'start_date' and 'end_date' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with 'start_date' and 'end_date' converted to datetime format.\n",
    "    \"\"\"\n",
    "    if 'start_date' in df.columns and 'end_date' in df.columns:\n",
    "        try:\n",
    "            df.loc[:, 'start_date'] = pd.to_datetime(df['start_date'], dayfirst=False)\n",
    "            df.loc[:, 'end_date'] = pd.to_datetime(df['end_date'], dayfirst=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting dates: {e}\")\n",
    "    else:\n",
    "        print(\"Warning: 'start_date' or 'end_date' columns are missing in the dataframe.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Membership of Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.581272Z",
     "iopub.status.busy": "2025-03-12T08:59:47.581272Z",
     "iopub.status.idle": "2025-03-12T08:59:47.584740Z",
     "shell.execute_reply": "2025-03-12T08:59:47.584740Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_membership_columns(data, councils, file_date):\n",
    "    for col_name, council_data in councils:\n",
    "        # Check if council is active during the given date\n",
    "        is_active = (file_date >= council_data['start_date'].iloc[0]) & (file_date <= council_data['end_date'].iloc[0])\n",
    "        if is_active:\n",
    "            # Add membership column for active councils\n",
    "            data[col_name] = data['delegate'].apply(\n",
    "                lambda x: 1 if x.lower() in council_data['address'].str.lower().values else 0   \n",
    "            )\n",
    "        else:\n",
    "            # Default to 0 if not active \n",
    "            data[col_name] = 0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Voting Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.588754Z",
     "iopub.status.busy": "2025-03-12T08:59:47.587794Z",
     "iopub.status.idle": "2025-03-12T08:59:47.592957Z",
     "shell.execute_reply": "2025-03-12T08:59:47.592957Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_voting_power(data):\n",
    "    \n",
    "    # Calculate and assign voting power percentages based on active membership\n",
    "    sum_vp = data[data['voting_power'] > 1]['voting_power'].sum()\n",
    "    data['th_vp'] = data.apply(lambda row: (row['voting_power'] * 100) / sum_vp if row['voting_power'] > 1 else 0, axis=1)\n",
    "\n",
    "    # Define the councils and committees along with their membership columns\n",
    "    councils_and_committees = [\n",
    "        ('ch_member_r2', 'ch_vp_r2'),\n",
    "        ('ch_member_r3', 'ch_vp_r3'),\n",
    "        ('ch_member_r4', 'ch_vp_r4'),\n",
    "        ('ch_member_r5', 'ch_vp_r5'),\n",
    "        ('ch_member_r6', 'ch_vp_r6'),\n",
    "        ('gc_member_s3', 'gc_vp_s3'),\n",
    "        ('gc_member_s4', 'gc_vp_s4'),\n",
    "        ('gc_member_s5', 'gc_vp_s5'),\n",
    "        ('gc_member_mm_s5', 'gc_vp_mm_s5'),\n",
    "        ('dab_member_s5', 'dab_vp_s5'),\n",
    "        ('coc_member_s5', 'coc_vp_s5'),\n",
    "        ('gc_member_s6', 'gc_vp_s6'),\n",
    "        ('gc_member_mm_s6', 'gc_vp_mm_s6'),\n",
    "        ('dab_member_s6', 'dab_vp_s6'),\n",
    "        ('coc_member_s6', 'coc_vp_s6'),\n",
    "        ('gc_member_s7', 'gc_vp_s7'),\n",
    "        ('gc_member_op_s7','gc_vp_op_s7'),\n",
    "        ('dab_member_s7','dab_vp_s7'),\n",
    "        ('mmc_member_s7','mmc_vp_s7')\n",
    "    ]\n",
    "\n",
    "    # Loop through each council/committee to calculate the voting power percentage\n",
    "    for member_col, vp_col in councils_and_committees:\n",
    "        count_member = data[member_col].sum() \n",
    "        data[vp_col] = data.apply(\n",
    "            lambda row: (row[member_col] * 100) / count_member if row[member_col] == 1 else 0, axis=1\n",
    "        )\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.596969Z",
     "iopub.status.busy": "2025-03-12T08:59:47.596969Z",
     "iopub.status.idle": "2025-03-12T08:59:47.736138Z",
     "shell.execute_reply": "2025-03-12T08:59:47.736138Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def create_data_sheet(data, filename):\n",
    "    MONGO_URI = os.getenv('MONGODB_URI')\n",
    "    DATABASE_NAME = 'CPI'\n",
    "    COLLECTION_NAME = 'delegate_data'\n",
    "\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        db = client[DATABASE_NAME]\n",
    "        collection = db[COLLECTION_NAME]\n",
    "\n",
    "        new_version = int(datetime.utcnow().timestamp())\n",
    "        file_date = datetime.strptime(filename[:-4], '%Y-%m-%d')\n",
    "        \n",
    "        # Load data from other CSV files\n",
    "        citizens_round2 = pd.read_csv(\"./Data/Round 2.csv\", encoding='latin1')\n",
    "        citizens_round3 = pd.read_csv(\"./Data/Round 3.csv\", encoding='latin1')\n",
    "        citizens_round4 = pd.read_csv(\"./Data/Round 4.csv\", encoding='latin1')\n",
    "        citizens_round5 = pd.read_csv(\"./Data/Round 5.csv\", encoding='latin1')\n",
    "        citizens_round6 = pd.read_csv(\"./Data/Round 6.csv\", encoding='latin1')\n",
    "        grants = pd.read_csv(\"./Data/Grants_Council.csv\", encoding='latin1')\n",
    "        grants_mm = pd.read_csv(\"./Data/Grants_Council_MM.csv\", encoding='latin1')\n",
    "        grants_op = pd.read_csv(\"./Data/Grants_Council_Operations.csv\", encoding='latin1')\n",
    "        dab = pd.read_csv(\"./Data/Developer_Advisory_Board.csv\", encoding='latin1')\n",
    "        coc = pd.read_csv(\"./Data/Code_of_Conduct_Council.csv\", encoding='latin1')\n",
    "        mmc = pd.read_csv(\"./Data/Milestone_and_Metrics_Council.csv\", encoding='latin1')\n",
    "        \n",
    "\n",
    "        # Drop rows with null values in the 'address' column for each DataFrame\n",
    "        citizens_round2.dropna(subset=['address'], inplace=True)\n",
    "        citizens_round3.dropna(subset=['address'], inplace=True)\n",
    "        citizens_round4.dropna(subset=['address'], inplace=True)\n",
    "        citizens_round5.dropna(subset=['address'], inplace=True)\n",
    "        citizens_round6.dropna(subset=['address'], inplace=True)\n",
    "\n",
    "        grants.dropna(subset=['address'], inplace=True)\n",
    "        grants_mm.dropna(subset=['address'], inplace=True)\n",
    "        grants_op.dropna(subset=['address'], inplace=True)\n",
    "        dab.dropna(subset=['address'], inplace=True)\n",
    "        coc.dropna(subset=['address'], inplace=True)\n",
    "        mmc.dropna(subset=['address'], inplace=True)\n",
    "\n",
    "        # Filter grants data by season \n",
    "        grants_season3 = grants[grants['season'] == 3]\n",
    "\n",
    "        grants_season4 = grants[grants['season'] == 4]\n",
    "\n",
    "        grants_season5 = grants[grants['season'] == 5]\n",
    "        grants_mm_season5 = grants_mm[grants_mm['season'] == 5]\n",
    "        dab_season5 = dab[dab[\"season\"] == 5]\n",
    "        coc_season5 = coc[coc[\"season\"] == 5]\n",
    "\n",
    "        grants_season6 = grants[grants['season'] == 6]\n",
    "        grants_mm_season6 = grants_mm[grants_mm['season'] == 6]\n",
    "        dab_season6 = dab[dab[\"season\"] == 6]\n",
    "        coc_season6 = coc[coc[\"season\"] == 6]\n",
    "\n",
    "        grants_season7 = grants[grants['season'] == 7]\n",
    "        grants_op_season7 = grants_op[grants_op['season'] == 7]\n",
    "        dab_season7 = dab[dab[\"season\"] == 7]\n",
    "        mmc_season7 = mmc[mmc[\"season\"] == 7]\n",
    "\n",
    "        # Calling the function and capturing the returned data\n",
    "        citizens_round2 = convert_dates(citizens_round2)\n",
    "        citizens_round3 = convert_dates(citizens_round3)\n",
    "        citizens_round4 = convert_dates(citizens_round4)\n",
    "        citizens_round5 = convert_dates(citizens_round5)\n",
    "        citizens_round6 = convert_dates(citizens_round6)\n",
    "        grants_season3 = convert_dates(grants_season3)\n",
    "        grants_season4 = convert_dates(grants_season4)\n",
    "        grants_season5 = convert_dates(grants_season5)\n",
    "        grants_mm_season5 = convert_dates(grants_mm_season5)\n",
    "        dab_season5 = convert_dates(dab_season5)\n",
    "        coc_season5 = convert_dates(coc_season5)\n",
    "        grants_season6 = convert_dates(grants_season6)\n",
    "        grants_mm_season6 = convert_dates(grants_mm_season6)\n",
    "        dab_season6 = convert_dates(dab_season6)\n",
    "        coc_season6 = convert_dates(coc_season6)\n",
    "\n",
    "        grants_season7 = convert_dates(grants_season7)\n",
    "        grants_op_season7 = convert_dates(grants_op_season7)\n",
    "        dab_season7 = convert_dates(dab_season7)\n",
    "        mmc_season7 = convert_dates(mmc_season7)\n",
    "\n",
    "        # Add missing delegates from various rounds and councils\n",
    "        data = add_missing_delegates(data, citizens_round2)\n",
    "        data = add_missing_delegates(data, citizens_round3)\n",
    "        data = add_missing_delegates(data, citizens_round4)\n",
    "        data = add_missing_delegates(data, citizens_round5)\n",
    "        data = add_missing_delegates(data, citizens_round6)\n",
    "        data = add_missing_delegates(data, grants_season3)\n",
    "        data = add_missing_delegates(data, grants_season4)\n",
    "        data = add_missing_delegates(data, grants_season5)\n",
    "        data = add_missing_delegates(data, grants_mm_season5)\n",
    "        data = add_missing_delegates(data, dab_season5)\n",
    "        data = add_missing_delegates(data, coc_season5)\n",
    "        data = add_missing_delegates(data, grants_season6)\n",
    "        data = add_missing_delegates(data, grants_mm_season6)\n",
    "        data = add_missing_delegates(data, dab_season6)\n",
    "        data = add_missing_delegates(data, coc_season6)\n",
    "        data = add_missing_delegates(data, grants_season7)\n",
    "        data = add_missing_delegates(data, grants_op_season7)\n",
    "        data = add_missing_delegates(data, dab_season7)\n",
    "        data = add_missing_delegates(data, mmc_season7)\n",
    "        \n",
    "        # Add the columns \n",
    "        data['th_vp'] = None\n",
    "        data['ch_member_r2'] = None\n",
    "        data['ch_vp_r2'] = None\n",
    "        data['ch_member_r3'] = None\n",
    "        data['ch_vp_r3'] = None\n",
    "        data['ch_member_r4'] = None\n",
    "        data['ch_vp_r4'] = None\n",
    "        data['ch_member_r5'] = None\n",
    "        data['ch_vp_r5'] = None\n",
    "        data['ch_member_r6'] = None\n",
    "        data['ch_vp_r6'] = None\n",
    "\n",
    "        data['gc_member_s3'] = None\n",
    "        data['gc_vp_s3'] = None\n",
    "        data['gc_member_s4'] = None\n",
    "        data['gc_vp_s4'] = None\n",
    "\n",
    "        data['gc_member_s5'] = None\n",
    "        data['gc_vp_s5'] = None\n",
    "        data['gc_member_mm_s5'] = None\n",
    "        data['gc_vp_mm_s5'] = None\n",
    "        data['sc_member_s5'] = None\n",
    "        data['sc_vp_s5'] = None\n",
    "        data['coc_member_s5'] = None\n",
    "        data['coc_vp_s5'] = None\n",
    "        data['dab_member_s5'] = None\n",
    "        data['dab_vp_s5'] = None\n",
    "\n",
    "        data['gc_member_s6'] = None\n",
    "        data['gc_vp_s6'] = None\n",
    "        data['gc_member_mm_s6'] = None\n",
    "        data['gc_vp_mm_s6'] = None\n",
    "        data['sc_member_s6'] = None\n",
    "        data['sc_vp_s6'] = None\n",
    "        data['coc_member_s6'] = None\n",
    "        data['coc_vp_s6'] = None\n",
    "        data['dab_member_s6'] = None\n",
    "        data['dab_vp_s6'] = None\n",
    "\n",
    "        data['gc_member_s7'] = None\n",
    "        data['gc_vp_s7'] = None\n",
    "        data['gc_member_op_s7'] = None\n",
    "        data['gc_vp_op_s7'] = None\n",
    "        data['sc_member_s7'] = None\n",
    "        data['sc_vp_s7'] = None\n",
    "        data['dab_member_s7'] = None\n",
    "        data['dab_vp_s7'] = None\n",
    "        data['mmc_member_s7'] = None\n",
    "        data['mmc_vp_s7'] = None\n",
    "\n",
    "        councils = [\n",
    "        ('ch_member_r2', citizens_round2),\n",
    "        ('ch_member_r3', citizens_round3),\n",
    "        ('ch_member_r4', citizens_round4),\n",
    "        ('ch_member_r5', citizens_round5),\n",
    "        ('ch_member_r6', citizens_round6),\n",
    "        ('gc_member_s3', grants_season3),\n",
    "        ('gc_member_s4', grants_season4),\n",
    "        ('gc_member_s5', grants_season5),\n",
    "        ('gc_member_mm_s5', grants_mm_season5),\n",
    "        ('dab_member_s5', dab_season5),\n",
    "        ('coc_member_s5', coc_season5),\n",
    "        ('gc_member_s6', grants_season6),\n",
    "        ('gc_member_mm_s6', grants_mm_season6),\n",
    "        ('dab_member_s6', dab_season6),\n",
    "        ('coc_member_s6', coc_season6),\n",
    "        ('gc_member_s7', grants_season7),\n",
    "        ('gc_member_op_s7', grants_op_season7),\n",
    "        ('dab_member_s7', dab_season7),\n",
    "        ('mmc_member_s7', mmc_season7)\n",
    "    ]\n",
    "\n",
    "        # Add membership columns dynamically\n",
    "        data = add_membership_columns(data, councils, file_date)\n",
    "        print(\"Membership columns added successfully!\",data)\n",
    "\n",
    "        data = assign_voting_power(data)\n",
    "\n",
    "        # Fill all null values in the dataframe with 0\n",
    "        data.fillna(0, inplace=True)\n",
    "        # Create bulk operations\n",
    "        bulk_operations = []\n",
    "        current_time = datetime.utcnow()\n",
    "\n",
    "        for _, row in data.iterrows():\n",
    "            voting_power = {\n",
    "                'vp': float(row['voting_power']) if 'voting_power' in row else 0,\n",
    "                'th_vp': float(row['th_vp']) if 'th_vp' in row else 0\n",
    "            }\n",
    "            \n",
    "            vp_columns = [\n",
    "                'ch_vp_r2', 'ch_vp_r3', 'ch_vp_r4', 'ch_vp_r5', 'ch_vp_r6',\n",
    "                'gc_vp_s3', 'gc_vp_s4', 'gc_vp_s5', 'gc_vp_mm_s5',\n",
    "                'gc_vp_s6', 'gc_vp_mm_s6', 'sc_vp_s5', 'sc_vp_s6',\n",
    "                'coc_vp_s5', 'coc_vp_s6', 'dab_vp_s5', 'dab_vp_s6', 'gc_vp_s7',\n",
    "                'gc_vp_op_s7','dab_vp_s7','mmc_vp_s7'\n",
    "            ]\n",
    "            \n",
    "            for col in vp_columns:\n",
    "                if row.get(col) is not None and row[col] != 0:\n",
    "                    voting_power[col] = row[col]\n",
    "            \n",
    "            update_data = {\n",
    "                \"date\": file_date,\n",
    "                \"delegate_id\": row['delegate'],\n",
    "                \"voting_power\": voting_power,\n",
    "                \"updatedAt\": current_time,\n",
    "                \"version\": new_version\n",
    "            }\n",
    "\n",
    "            # Create update operation\n",
    "            bulk_operations.append(\n",
    "                UpdateOne(\n",
    "                    {\n",
    "                        \"delegate_id\": row['delegate'],\n",
    "                        \"date\": file_date\n",
    "                    },\n",
    "                    {\"$set\": update_data},\n",
    "                    upsert=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            # Execute bulk operations\n",
    "            if bulk_operations:\n",
    "                result = collection.bulk_write(bulk_operations, ordered=False)\n",
    "                print(f\"Processed documents - Inserted: {result.upserted_count}, Modified: {result.modified_count}\")\n",
    "\n",
    "            # Delete old versions\n",
    "            delete_result = collection.delete_many({\n",
    "                \"version\": {\"$ne\": new_version},\n",
    "            })\n",
    "            print(f\"Deleted {delete_result.deleted_count} old version documents\")\n",
    "            \n",
    "            print(f\"Data from {filename} saved to MongoDB successfully!\")\n",
    "            return data\n",
    "\n",
    "        except pymongo.errors.BulkWriteError as bwe:\n",
    "            # Handle partial success in bulk write\n",
    "            print(f\"Bulk write partial error: {bwe.details}\")\n",
    "            # Cleanup only if no documents were successfully updated\n",
    "            if bwe.details.get('nInserted', 0) == 0 and bwe.details.get('nModified', 0) == 0:\n",
    "                collection.delete_many({\"version\": new_version})\n",
    "                print(f\"Cleaned up version {new_version} due to complete failure\")\n",
    "            raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "def read_latest_delegate_data(date=None):\n",
    "    try:\n",
    "        client = MongoClient(os.getenv('MONGODB_URI'))\n",
    "        db = client['CPI']\n",
    "        collection = db['delegate_data']\n",
    "\n",
    "        # Query filter\n",
    "        query = {}\n",
    "        if date:\n",
    "            query[\"date\"] = date\n",
    "\n",
    "        # Find the latest version for the given date or overall\n",
    "        latest_doc = collection.find_one(\n",
    "            query,\n",
    "            sort=[(\"version\", pymongo.DESCENDING)]\n",
    "        )\n",
    "\n",
    "        if not latest_doc:\n",
    "            return []\n",
    "\n",
    "        # Get all documents with the latest version and matching date if specified\n",
    "        query[\"version\"] = latest_doc[\"version\"]\n",
    "        latest_data = list(collection.find(query))\n",
    "\n",
    "        return latest_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading latest data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate HHI and CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.740159Z",
     "iopub.status.busy": "2025-03-12T08:59:47.740159Z",
     "iopub.status.idle": "2025-03-12T08:59:47.748582Z",
     "shell.execute_reply": "2025-03-12T08:59:47.748582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define each influence period with start_date, end_date, and influence percentages\n",
    "influence_periods = [\n",
    "    # May 26th, 2022 - January 25th, 2023\n",
    "    {\n",
    "        \"start_date\": \"2022-05-26\", \"end_date\": \"2023-01-25\",\n",
    "        \"influences\": {\"th_vp\": 48.32, \"ch_vp_r2\": 51.68}\n",
    "    },\n",
    "    # January 26th, 2023 - March 30th, 2023\n",
    "    {\n",
    "        \"start_date\": \"2023-01-26\", \"end_date\": \"2023-03-30\",\n",
    "        \"influences\": {\"th_vp\": 41.95, \"ch_vp_r2\": 44.88, \"gc_vp_s3\": 13.17}\n",
    "    },\n",
    "    # March 31st, 2023 - June 7th, 2023\n",
    "    {\n",
    "        \"start_date\": \"2023-03-31\", \"end_date\": \"2023-06-07\",\n",
    "        \"influences\": {\"th_vp\": 41.95, \"ch_vp_r3\": 44.88, \"gc_vp_s3\": 13.17}\n",
    "    },\n",
    "    # June 8th, 2023 - January 3rd, 2024\n",
    "    {\n",
    "        \"start_date\": \"2023-06-08\", \"end_date\": \"2024-01-03\",\n",
    "        \"influences\": {\"th_vp\": 41.95, \"ch_vp_r3\": 44.88, \"gc_vp_s4\": 13.17}\n",
    "    },\n",
    "    # January 4th, 2024 - January 11th, 2024\n",
    "    {\n",
    "        \"start_date\": \"2024-01-04\", \"end_date\": \"2024-01-11\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 32.33, \"ch_vp_r3\": 34.59, \"gc_vp_s5\": 10.15,\n",
    "            \"gc_vp_mm_s5\": 2.82, \"sc_vp_s5\": 12.78, \"coc_vp_s5\": 4.32,\n",
    "            \"dab_vp_s5\": 3.01\n",
    "        }\n",
    "    },\n",
    "    # January 12th, 2024 - June 26th, 2024\n",
    "    {\n",
    "        \"start_date\": \"2024-01-12\", \"end_date\": \"2024-06-26\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 32.33, \"ch_vp_r4\": 34.59, \"gc_vp_s5\": 10.15,\n",
    "            \"gc_vp_mm_s5\": 2.82, \"sc_vp_s5\": 12.78, \"coc_vp_s5\": 4.32,\n",
    "            \"dab_vp_s5\": 3.01\n",
    "        }\n",
    "    },\n",
    "    # June 27th, 2024 - July 16th, 2024\n",
    "    {\n",
    "        \"start_date\": \"2024-06-27\", \"end_date\": \"2024-07-16\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 32.33, \"ch_vp_r4\": 34.59, \"gc_vp_s6\": 10.15,\n",
    "            \"gc_vp_mm_s6\": 2.82, \"sc_vp_s6\": 12.78, \"coc_vp_s6\": 4.32,\n",
    "            \"dab_vp_s6\": 3.01\n",
    "        }\n",
    "    },\n",
    "    # July 17th, 2024 - October 21st, 2024\n",
    "    {\n",
    "        \"start_date\": \"2024-07-17\", \"end_date\": \"2024-10-21\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 32.33, \"ch_vp_r5\": 34.59, \"gc_vp_s6\": 10.15,\n",
    "            \"gc_vp_mm_s6\": 2.82, \"sc_vp_s6\": 12.78, \"coc_vp_s6\": 4.32,\n",
    "            \"dab_vp_s6\": 3.01\n",
    "        }\n",
    "    },\n",
    "    # October 22nd, 2024 - January 15th, 2025\n",
    "    {\n",
    "        \"start_date\": \"2024-10-22\", \"end_date\": \"2025-01-15\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 32.33, \"ch_vp_r6\": 34.59, \"gc_vp_s6\": 10.15,\n",
    "            \"gc_vp_mm_s6\": 2.82, \"sc_vp_s6\": 12.78, \"coc_vp_s6\": 4.32,\n",
    "            \"dab_vp_s6\": 3.01\n",
    "        }\n",
    "    },\n",
    "    # January 16th, 2025 - June 11th, 2025\n",
    "    {\n",
    "        \"start_date\": \"2025-01-16\", \"end_date\": \"2025-06-11\",\n",
    "        \"influences\": {\n",
    "            \"th_vp\": 33.73, \"ch_vp_r6\": 36.08, \"gc_vp_s7\": 10.59,\n",
    "            \"gc_vp_op_s7\": 0.19, \"sc_vp_s7\": 13.33, \"dab_vp_s7\": 3.14,\n",
    "            \"mmc_vp_s7\": 2.94\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate_influence(row, influences):\n",
    "    \"\"\"Calculates influence based on influence percentages per column.\"\"\"\n",
    "    influence_sum = sum(row.get(col, 0) * (val / 100) for col, val in influences.items())\n",
    "    return influence_sum\n",
    "\n",
    "def add_influence_column(df, file_date_str):\n",
    "    \"\"\"Adds 'influence' column to DataFrame based on file date.\"\"\"\n",
    "    file_date = datetime.strptime(file_date_str, \"%Y-%m-%d\")\n",
    "    for period in influence_periods:\n",
    "        start_date = datetime.strptime(period[\"start_date\"], \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(period[\"end_date\"], \"%Y-%m-%d\")\n",
    "        if start_date <= file_date <= end_date:\n",
    "            df[\"influence\"] = df.apply(calculate_influence, axis=1, influences=period[\"influences\"])\n",
    "            break\n",
    "    return df\n",
    "\n",
    "def calculate_HHI_and_CPI(data, file_date_str):\n",
    "    \"\"\"\n",
    "    Calculate HHI and CPI based on the data and remove the temporary file afterward.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The processed data.\n",
    "        file_date_str (str): The date string extracted from the filename.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: HHI and CPI values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Perform calculations\n",
    "        data = add_influence_column(data, file_date_str)\n",
    "        data['th_vp_squared'] = data['th_vp'] ** 2\n",
    "        data['influence_squared'] = data['influence'] ** 2\n",
    "        HHI = round(data['th_vp_squared'].sum(), 2)\n",
    "        CPI = round(data['influence_squared'].sum(), 2)\n",
    "\n",
    "        print(f\"Date: {file_date_str} | HHI: {HHI} | CPI: {CPI}\")\n",
    "        return HHI, CPI\n",
    "    finally:\n",
    "        # Construct the file path\n",
    "        file_path = f\"./Data/{file_date_str}.csv\"\n",
    "        \n",
    "        # Remove the file if it exists\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"Temporary file removed: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T08:59:47.751604Z",
     "iopub.status.busy": "2025-03-12T08:59:47.751604Z",
     "iopub.status.idle": "2025-03-12T09:00:28.193830Z",
     "shell.execute_reply": "2025-03-12T09:00:28.192768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashp\\AppData\\Local\\Temp\\ipykernel_31696\\2114150361.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  active_season['address'] = active_season['address'].str.lower()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashp\\AppData\\Local\\Temp\\ipykernel_31696\\1704696040.py:20: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  new_version = int(datetime.utcnow().timestamp())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership columns added successfully!                                         delegate  voting_power th_vp  \\\n",
      "0     0x2ac5393d1f4be4ef89b45ee2f93d7f20a5cf6d5a  7.024585e+06  None   \n",
      "1     0x1b686ee8e31c5959d9f5bbd8122a58682788eead  5.738282e+06  None   \n",
      "2     0x06ad892ce23c136bbda3a821570343a2af3e2914  5.418460e+06  None   \n",
      "3     0xf11b6a8c3cb8bb7dbc1518a613b10ceb0bbfc06b  5.219295e+06  None   \n",
      "4     0xeff8d84e0fd304550da242040ccd45bd44ce71f1  5.008845e+06  None   \n",
      "...                                          ...           ...   ...   \n",
      "5133  0xe7aa7af667016837733f3ca3809bde04697730ef  0.000000e+00  None   \n",
      "5134  0x436c7f148cc5dbc90b5531278c87877bdbd83e27  0.000000e+00  None   \n",
      "5135  0xa8f0048a0d1a04663ca5010d0beac5bcaeea0eef  0.000000e+00  None   \n",
      "5136  0xe2a0464f8ae3bd34b6cb1e578c1110321f491b72  0.000000e+00  None   \n",
      "5137  0xd7e7bca98ab9fb25e17ad73429e89a40b55708be  0.000000e+00  None   \n",
      "\n",
      "      ch_member_r2 ch_vp_r2  ch_member_r3 ch_vp_r3  ch_member_r4 ch_vp_r4  \\\n",
      "0                0     None             0     None             0     None   \n",
      "1                0     None             0     None             0     None   \n",
      "2                0     None             0     None             0     None   \n",
      "3                0     None             0     None             0     None   \n",
      "4                0     None             0     None             0     None   \n",
      "...            ...      ...           ...      ...           ...      ...   \n",
      "5133             0     None             0     None             0     None   \n",
      "5134             0     None             0     None             0     None   \n",
      "5135             0     None             0     None             0     None   \n",
      "5136             0     None             0     None             0     None   \n",
      "5137             0     None             0     None             0     None   \n",
      "\n",
      "      ch_member_r5  ... gc_member_s7  gc_vp_s7 gc_member_op_s7  gc_vp_op_s7  \\\n",
      "0                0  ...            0      None               0         None   \n",
      "1                0  ...            0      None               0         None   \n",
      "2                0  ...            0      None               0         None   \n",
      "3                0  ...            0      None               0         None   \n",
      "4                0  ...            0      None               0         None   \n",
      "...            ...  ...          ...       ...             ...          ...   \n",
      "5133             0  ...            0      None               0         None   \n",
      "5134             0  ...            0      None               0         None   \n",
      "5135             0  ...            0      None               0         None   \n",
      "5136             0  ...            0      None               0         None   \n",
      "5137             0  ...            0      None               0         None   \n",
      "\n",
      "     sc_member_s7  sc_vp_s7 dab_member_s7  dab_vp_s7 mmc_member_s7  mmc_vp_s7  \n",
      "0            None      None             0       None             0       None  \n",
      "1            None      None             0       None             0       None  \n",
      "2            None      None             0       None             0       None  \n",
      "3            None      None             0       None             0       None  \n",
      "4            None      None             0       None             0       None  \n",
      "...           ...       ...           ...        ...           ...        ...  \n",
      "5133         None      None             0       None             0       None  \n",
      "5134         None      None             1       None             0       None  \n",
      "5135         None      None             0       None             0       None  \n",
      "5136         None      None             1       None             0       None  \n",
      "5137         None      None             0       None             1       None  \n",
      "\n",
      "[5138 rows x 47 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashp\\AppData\\Local\\Temp\\ipykernel_31696\\1704696040.py:194: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.fillna(0, inplace=True)\n",
      "C:\\Users\\yashp\\AppData\\Local\\Temp\\ipykernel_31696\\1704696040.py:197: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  current_time = datetime.utcnow()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents - Inserted: 0, Modified: 5138\n",
      "Deleted 0 old version documents\n",
      "Data from 2025-03-12.csv saved to MongoDB successfully!\n",
      "Date: 2025-03-12 | HHI: 220.2 | CPI: 75.56\n",
      "Temporary file removed: ./Data/2025-03-12.csv\n"
     ]
    }
   ],
   "source": [
    "data, filename = fetch_top_5000_delegates()\n",
    "\n",
    "data = distribute_ACC_Power(data, filename)\n",
    "\n",
    "data = create_data_sheet(data, filename)\n",
    "\n",
    "file_date_str = os.path.splitext(filename)[0] \n",
    "hhi, cpi = calculate_HHI_and_CPI(data, file_date_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
